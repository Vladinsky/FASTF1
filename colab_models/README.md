# Formula 1 Tire Change Prediction - Google Colab Edition ðŸŽï¸

Versione completa ottimizzata per Google Colab Pro del sistema di predizione cambi gomme F1 con RNN multi-task e inference real-time.

## ðŸš€ Caratteristiche Principali

### **Colab Pro Optimized Features**
- ðŸ”— **Google Drive Integration**: Unione automatica dati distribuiti
- ðŸ§  **Training da Zero**: Pipeline completa per training from scratch
- âš¡ **GPU Acceleration**: Ottimizzato per T4/A100 con mixed precision
- ðŸŽ¯ **Real-time Inference**: Sistema completo per predizioni live
- ðŸ’¾ **Memory Management**: Gestione intelligente 25GB RAM Colab Pro

### **Advanced ML Pipeline**
- ðŸŽ¯ **Multi-task Learning**: Predizione cambio + tipo mescola
- ðŸ“Š **Imbalanced Learning**: Weighted loss per target sbilanciato (3.3%)
- ðŸ”„ **Sequence Modeling**: LSTM per dati sequenziali (10 timesteps)
- ðŸ“ˆ **Performance Tracking**: Monitoring completo training + evaluation
- ðŸŽ›ï¸ **Hyperparameter Tuning**: Ottimizzazione automatica parametri

### **Production Ready**
- ðŸš€ **API Server**: REST API per inference in tempo reale
- ðŸ“± **Web Interface**: Dashboard interattivo per demo
- ðŸ“Š **Advanced Visualizations**: Analisi predizioni e performance
- ðŸ”§ **Model Versioning**: Gestione automatica checkpoint e versioni

## ðŸ“‹ Prerequisiti

1. **Google Colab Pro** (raccomandato per GPU A100 e 25GB RAM)
2. **Google Drive** con dati F1 caricati
3. **Account Google** per mount automatico Drive

## ðŸ› ï¸ Quick Start Guide

### Step 1: Setup Ambiente

```python
# Su Google Colab, esegui questa cella per setup completo
!git clone https://github.com/your-repo/f1-tire-prediction.git
%cd f1-tire-prediction/colab_models

# Setup automatico ambiente
%run setup_colab_pro.py
```

### Step 2: Unione Dati Distribuiti

```python
# I dati sono attualmente distribuiti in piÃ¹ cartelle su Drive
# Lo script li unirÃ  automaticamente in un dataset unico

from data.data_unifier_complete import CompleteDataUnifier

unifier = CompleteDataUnifier()
dataset = unifier.unify_all_data()
print(f"Dataset finale: {len(dataset)} righe")
```

### Step 3: Training Completo

```python
# Training da zero con parametri ottimizzati per Colab Pro
from training.train_from_scratch_pro import ProTrainer

trainer = ProTrainer()
model = trainer.train_complete()
```

### Step 4: Evaluation & Inference

```python
# Valutazione modello
from models.evaluation_advanced import AdvancedEvaluator
evaluator = AdvancedEvaluator()
results = evaluator.evaluate_model(model)

# Setup inference real-time
from inference.real_time_predictor import RealTimePredictor
predictor = RealTimePredictor(model)
```

## ðŸ“ Struttura Progetto

```
colab_models/
â”œâ”€â”€ ðŸ“‹ README.md                    # Questa guida
â”œâ”€â”€ ðŸš€ setup_colab_pro.py          # Setup automatico ambiente
â”œâ”€â”€ ðŸ“¦ requirements_pro.txt         # Dipendenze ottimizzate
â”‚
â”œâ”€â”€ ðŸ“Š configs/                     # Configurazioni
â”‚   â”œâ”€â”€ model_config_pro.yaml      # Config modello Pro
â”‚   â”œâ”€â”€ training_config_pro.json   # Parametri training
â”‚   â”œâ”€â”€ data_config_unified.json   # Config unione dati
â”‚   â””â”€â”€ inference_config.json      # Config inference
â”‚
â”œâ”€â”€ ðŸ§  models/                      # Architettura modelli
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ lstm_pro_architecture.py   # LSTM ottimizzato Pro
â”‚   â”œâ”€â”€ training_utils_pro.py      # Training utilities
â”‚   â”œâ”€â”€ evaluation_advanced.py     # Evaluation completa
â”‚   â”œâ”€â”€ data_loaders_pro.py        # Data loading Pro
â”‚   â””â”€â”€ inference_engine.py        # Engine inference
â”‚
â”œâ”€â”€ ðŸ“Š data/                        # Gestione dati
â”‚   â”œâ”€â”€ data_unifier_complete.py   # Unione dati distribuiti
â”‚   â”œâ”€â”€ data_preprocessor_pro.py   # Preprocessing Pro
â”‚   â”œâ”€â”€ data_validator.py          # Validazione dataset
â”‚   â””â”€â”€ data_augmentation.py       # Augmentation avanzato
â”‚
â”œâ”€â”€ ðŸ‹ï¸ training/                    # Pipeline training
â”‚   â”œâ”€â”€ train_from_scratch_pro.py  # Training principale
â”‚   â”œâ”€â”€ train_notebook_pro.ipynb   # Notebook interattivo
â”‚   â”œâ”€â”€ hyperparameter_tuning.py   # Tuning automatico
â”‚   â””â”€â”€ distributed_training.py    # Training distribuito
â”‚
â”œâ”€â”€ ðŸ”§ utils/                       # Utilities
â”‚   â”œâ”€â”€ colab_pro_helpers.py       # Helper Colab Pro
â”‚   â”œâ”€â”€ memory_management_pro.py   # Gestione 25GB RAM
â”‚   â”œâ”€â”€ drive_integration.py       # Integrazione Drive
â”‚   â”œâ”€â”€ monitoring_advanced.py     # Monitoring completo
â”‚   â””â”€â”€ notification_system.py     # Notifiche avanzate
â”‚
â”œâ”€â”€ ðŸš€ inference/                   # Sistema inference
â”‚   â”œâ”€â”€ real_time_predictor.py     # Predizioni real-time
â”‚   â”œâ”€â”€ web_interface.py           # Interface web
â”‚   â”œâ”€â”€ api_server.py              # API REST
â”‚   â””â”€â”€ visualization_engine.py    # Visualizzazioni
â”‚
â””â”€â”€ ðŸ““ notebooks/                   # Notebook completi
    â”œâ”€â”€ 01_quick_start_pro.ipynb   # Avvio rapido
    â”œâ”€â”€ 02_data_exploration.ipynb  # Esplorazione dati
    â”œâ”€â”€ 03_training_complete.ipynb # Training guidato
    â”œâ”€â”€ 04_model_evaluation.ipynb  # Valutazione modello
    â”œâ”€â”€ 05_hyperparameter_opt.ipynb # Ottimizzazione
    â””â”€â”€ 06_real_time_demo.ipynb    # Demo inference
```

## ðŸŽ¯ Features Avanzate

### **Unione Dati Intelligente**
- Consolida automaticamente dati da `domenicoDL/` e `Vincenzo/processed_races/`
- Validazione integritÃ  e consistenza cross-anni
- Bilanciamento automatico dataset per tutti gli anni
- Gestione duplicati e missing values

### **Training Ottimizzato Pro**
- **Mixed Precision**: 2x velocitÃ  training su GPU moderne
- **Dynamic Batch Sizing**: Adatta batch size alla memoria disponibile
- **Gradient Accumulation**: Simula batch piÃ¹ grandi
- **Smart Checkpointing**: Salvataggio automatico ogni 30min

### **Inference Real-time**
- **Sub-100ms latency**: Ottimizzato per predizioni veloci
- **Streaming pipeline**: Gestione dati live
- **REST API**: Integrazione semplice con applicazioni
- **Interactive dashboard**: Demo immediato

## ðŸ“Š Dataset e Performance

### **Dataset Finale Atteso**
- **Anni coperti**: 2018-2024 (tutti disponibili)
- **Righe totali**: ~150K+ (unendo tutti i dati)
- **Features**: 52 engineered features da RNN
- **Target balance**: ~3-5% cambi gomme (gestito con weighted loss)

### **Performance Target**
- **Training time**: 4-6 ore su Colab Pro
- **Model accuracy**: >85% con recall >80%
- **Inference latency**: <100ms
- **Memory usage**: <20GB (margine sicurezza su 25GB)

## ðŸ”§ Configurazioni Chiave

### **Memory Management**
```python
# Configurazione ottimizzata per Colab Pro
MEMORY_CONFIG = {
    "max_batch_size": 512,          # Sfrutta 25GB RAM
    "gradient_accumulation": 4,      # Batch virtuali
    "mixed_precision": True,         # FP16 per velocitÃ 
    "dynamic_loss_scaling": True     # StabilitÃ  numerica
}
```

### **Training Parameters**
```python
# Parametri ottimizzati per dataset completo
TRAINING_CONFIG = {
    "learning_rate": 1e-3,
    "weight_decay": 1e-4,
    "pos_weight": 29.0,              # Gestione sbilanciamento
    "alpha_primary": 0.92,           # Weight task primario
    "beta_secondary": 0.08,          # Weight task secondario
    "early_stopping_patience": 15
}
```

## ðŸš¨ Troubleshooting

### **Problemi Comuni**

**âŒ Out of Memory**
```python
# Riduci batch size automaticamente
from utils.memory_management_pro import auto_adjust_batch_size
batch_size = auto_adjust_batch_size()
```

**âŒ Dati non trovati**
```python
# Verifica mount Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)
```

**âŒ Training lento**
```python
# Verifica GPU assignment
import torch
print(f"GPU disponibile: {torch.cuda.is_available()}")
print(f"GPU name: {torch.cuda.get_device_name()}")
```

## ðŸ“± Demo e Esempi

### **Quick Demo**
```python
# Demo rapida con modello pre-addestrato
%run notebooks/06_real_time_demo.ipynb
```

### **Training Personalizzato**
```python
# Training con hyperparameters custom
from training.train_from_scratch_pro import ProTrainer

trainer = ProTrainer(
    learning_rate=5e-4,
    batch_size=256,
    epochs=50
)
model = trainer.train_complete()
```

### **API Usage**
```python
# Usa modello via API
import requests

response = requests.post('/predict', json={
    'tire_age': 15,
    'lap': 25,
    'position': 3,
    'weather': 'DRY'
})
prediction = response.json()
```

## ðŸ† Risultati Attesi

Con questa configurazione ottimizzata per Colab Pro:

âœ… **Training completo da zero** in 4-6 ore  
âœ… **Gestione dataset completo** (150K+ righe)  
âœ… **Inference real-time** (<100ms)  
âœ… **Performance elevate** (85%+ accuracy)  
âœ… **Monitoring avanzato** con dashboard  
âœ… **Production ready** con API e web interface  

---

## ðŸŽ‰ Ready to Start!

Segui i notebook nella cartella `notebooks/` per una guida step-by-step completa, o esegui direttamente il setup automatico con:

```python
%run setup_colab_pro.py
```

**Happy Racing! ðŸ**
