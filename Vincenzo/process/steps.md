# RNN Tire Change Prediction - Progress Tracker
=====================================================

## Obiettivo del Progetto
Creare una rete neurale ricorrente (RNN) multi-task per predire i cambi gomme in Formula 1, utilizzando dati sequenziali di telemetria e gara.

## FASE 1: Setup e Consolidamento ‚úÖ COMPLETATA
**Data completamento: 29/05/2025 12:16**

### Risultati Raggiunti ‚úÖ
- [x] **Struttura progetto completa**: Creata cartella `Vincenzo/dataset/` con architettura modulare
- [x] **README.md completo**: Documentazione dettagliata dell'architettura RNN multi-task
- [x] **Dataset consolidato**: 77,257 righe da 71 file parquet (6 anni di dati F1)
- [x] **32 colonne con features complete**: pneumatici, meteo, performance, gap temporali
- [x] **Qualit√† dati eccellente**: 0 errori nel processamento, missing values minimi (1.7%)
- [x] **Analisi esplorativa critica**: Target variable 3.32% (ratio 1:29 molto sbilanciato)
- [x] **Configurazione modello ottimizzata**: LSTM 3-layer, weighted loss pos_weight=29.0

### Dati Chiave Identificati
- **Dataset finale**: `Vincenzo/dataset/dataset.parquet` (3.3MB)
- **Target variable**: 2,565 cambi gomme vs 74,692 no-cambi (sbilanciamento critico 1:29)
- **Copertura temporale**: 2018-2021 (train), 2023 (val), 2024 (test)
- **Piloti unici**: 36, **Gare**: 71
- **Distribuzione mescole**: MEDIUM 29%, SOFT 26.6%, HARD 26.4%

### File Creati
- `Vincenzo/dataset/data_consolidation.py` - Script consolidamento
- `Vincenzo/dataset/dataset_explorer.py` - Analisi esplorativa  
- `Vincenzo/dataset/configs/model_config.yaml` - Configurazione completa modello
- `Vincenzo/dataset/README.md` - Documentazione architettura
- `Vincenzo/dataset/consolidation_report.txt` - Report dettagliato
- `Vincenzo/dataset/dataset.parquet` - Dataset finale consolidato

---

## FASE 2: Feature Engineering Avanzato ‚úÖ COMPLETATA
**Data inizio: 29/05/2025 12:32**
**Data completamento: 29/05/2025 13:57**

### Risultati Raggiunti ‚úÖ
- [x] **Fix normalizzazione posizione**: Corretto! P1=1, P2=2, etc. (logica F1 corretta)
- [x] **Script preprocessing completo**: `data_preprocessing.py` implementato con successo
- [x] **52 features engineered** da 32 originali (+62% espansione feature space)
- [x] **Target variables perfetti**: 2,565 cambi gomme identificati e validati
- [x] **Sequenze RNN pronte**: 59,967 training sequences (10 timesteps √ó 52 features)
- [x] **Split temporale robusto**: Train/Val/Test senza data leakage
- [x] **Artifacts salvati**: Scaler, encoders, feature mapping per inference

### Dati Finali Processati üìä
- **Training set**: 71,240 righe ‚Üí 59,967 sequenze (2.89% target)
- **Validation set**: 2,992 righe ‚Üí 2,464 sequenze (4.30% target)  
- **Test set**: 3,025 righe ‚Üí 2,511 sequenze (2.75% target)
- **Features per timestep**: 52 (da 32 originali)
- **Sequence length**: 10 giri precedenti
- **Missing values residui**: 688 (0.9% - gestiti appropriatamente)

### Features Implementate ‚úÖ
- [x] **Temporal Features**: lap_progress, stint_progress, position features corrette
- [x] **Performance Features**: trend degradazione, gap logaritmici, velocit√† degradazione  
- [x] **Weather Features**: stabilit√† meteo, condizioni difficili, delta temperature
- [x] **Domain Knowledge**: finestre pit F1, strategia stint, compound tipici
- [x] **Categorical Encoding**: 9 Compounds, 15 Teams, 27 Locations, 32 Drivers
- [x] **Robust Normalization**: RobustScaler su 39 features numeriche

### File Creati üìÅ
- `Vincenzo/dataset/data_preprocessing.py` - Script preprocessing completo
- `Vincenzo/dataset/preprocessed/` - Directory output:
  - `X_train.npy, X_val.npy, X_test.npy` - Sequenze RNN pronte
  - `y_change_train.npy, y_change_val.npy, y_change_test.npy` - Target primario
  - `y_type_train.npy, y_type_val.npy, y_type_test.npy` - Target secondario
  - `train_processed.parquet, val_processed.parquet, test_processed.parquet` - DataFrames
  - `encoders.pkl, scaler.pkl, feature_columns.pkl` - Artifacts per inference

### Correzioni Implementate ‚ö†Ô∏è‚Üí‚úÖ
- **Problema**: Normalizzazione posizione errata `(Position-1)/(drivers_in_race-1)`
- **Soluzione**: P1=1, P2=2, etc. Posizione assoluta mantiene significato F1
- **Features aggiunte**: position_inverted, is_top_3, is_points_position
- **Risultato**: Logica corretta che rispetta semantica Formula 1

---

## FASE 3: Implementazione Modello RNN ‚úÖ COMPLETATA
**Data inizio: 29/05/2025 18:01**
**Data completamento: 29/05/2025 18:10**

### Tasks Pianificati
- [ ] **Architettura modello**: `model_architecture.py`
  - [ ] Multi-task LSTM con shared trunk
  - [ ] Head per cambio gomme (sigmoid)
  - [ ] Head per tipo mescola (softmax, attivo condizionalmente)
  - [ ] Input shape: (batch_size, 10, 52)

- [ ] **Loss function**: 
  - [ ] Combined loss con alpha=0.92, beta=0.08
  - [ ] BCEWithLogitsLoss con pos_weight=29.0
  - [ ] CrossEntropyLoss per tipo mescola
  - [ ] Conditional activation logic

- [ ] **Training pipeline**: `training_pipeline.py`
  - [ ] DataLoader per sequenze (batch_size=64)
  - [ ] Training loop con early stopping
  - [ ] Validation metrics (F1, precision, recall target 80%)
  - [ ] Checkpoint management

---

## FASE 4: Training e Ottimizzazione üéØ TODO

### Tasks Pianificati
- [ ] **Hyperparameter tuning**
- [ ] **Cross-validation temporale**
- [ ] **Threshold optimization** per recall 80%
- [ ] **Model evaluation**: `evaluation_metrics.py`

---

## FASE 5: Production Ready üöÄ TODO

### Tasks Pianificati  
- [ ] **Model deployment**
- [ ] **Inference pipeline**
- [ ] **Monitoring system**

---

## Log delle Decisioni Importanti üìä

### 29/05/2025 12:16 - Configurazione Loss Function
- **Decisione**: pos_weight=29.0 basato su ratio reale dataset (1:29)
- **Rationale**: Sbilanciamento pi√π estremo del previsto (3.32% vs 5% stimato)
- **Impact**: Aumentato peso task primario alpha=0.92 (era 0.9)

### 29/05/2025 12:32 - Correzione Feature Engineering  
- **Problema**: Normalizzazione posizione errata `(Position-1)/(drivers_in_race-1)`
- **Correzione**: P1 sempre P1, posizione assoluta non relativa
- **Rationale**: Logica F1 corretta, prestazione non dipende da numero piloti in gara

### 29/05/2025 13:57 - Completamento Preprocessing
- **Risultato**: 52 features da 32 (+62% espansione)
- **Sequenze**: 59,967 training (10√ó52), 2,464 val, 2,511 test
- **Target distribution**: 2.89% train, 4.30% val, 2.75% test (bilanciato)
- **Qualit√†**: Missing values < 1%, encoding robusto, split temporale pulito

---

## Prossimi Step Immediati ‚ö°
1. **Creare architettura LSTM multi-task** in PyTorch
2. **Implementare training pipeline** con weighted loss
3. **Setup validation metrics** per ottimizzazione soglia
4. **Test inference pipeline** end-to-end

---

## Metriche di Successo üéØ
- **Recall target**: ‚â• 80% per cambi gomme
- **F1-Score**: Ottimizzato mantenendo recall constraint
- **Precision**: Bilanciata per minimizzare falsi positivi
- **Sbilanciamento**: Gestito con weighted loss + augmentation

---

## Status Attuale üìà
- **Fase 1**: ‚úÖ Completata (Dataset consolidato, 77K righe)
- **Fase 2**: ‚úÖ Completata (52 features, 60K sequenze RNN-ready)
- **Fase 3**: üîÑ Pronta per implementazione modello
- **Infrastruttura**: Solida e production-ready
- **Dati**: Alta qualit√†, bilanciamento gestito, features ricche

---

## Troubleshooting

### 30/05/2025 - Problema Formattazione Notebook in Colab
- **Problema**: Il file `colab_models/notebooks/01_quick_start_pro.ipynb` non viene visualizzato correttamente in Google Colab. Le celle non sono riconosciute, mentre VSCode lo interpreta correttamente.
- **Causa Probabile**: Il file `.ipynb` potrebbe essere salvato in un formato "script" (con commenti `# %% [markdown]` e `# %% [code]`) invece del formato JSON standard atteso da Colab.
- **Soluzione Proposta**:
    1. Aprire `01_quick_start_pro.ipynb` in VSCode.
    2. Usare "File" > "Save As..." e assicurarsi che il tipo file sia "Jupyter Notebook (\*.ipynb)".
    3. Salvare il file (sovrascrivendo o con nuovo nome).
    4. Ricaricare il file su Google Drive e riaprirlo in Colab.
- **Stato**: ‚úÖ Risolto (Verificato che il file √® gi√† in formato JSON corretto dopo il salvataggio dell'utente).

### 30/05/2025 - Percorsi Dati Errati nel Notebook Colab
- **Problema**: La cella `<check_data>` nel notebook `colab_models/notebooks/01_quick_start_pro.ipynb` utilizza percorsi non corretti (`/content/drive/MyDrive/domenicoDL` e `/content/drive/MyDrive/Vincenzo/processed_races`) per localizzare i file di dati.
- **Correzione Indicata**: I dati `.parquet` si trovano in un unico percorso: `/content/drive/MyDrive/F1_Project/preprocessed_races`.
- **Soluzione Proposta**:
    1. Modificare la cella `<check_data>` per utilizzare il percorso corretto.
    2. Rimuovere o adattare i riferimenti ai percorsi `domenico_path` e `vincenzo_path` non pi√π validi.
    3. Verificare che la cella `<unify_data>` (che usa `CompleteDataUnifier`) sia compatibile con la lettura dei dati da questo singolo percorso.
- **Stato**: ‚úÖ Risolto (Notebook aggiornato con il percorso dati corretto).
